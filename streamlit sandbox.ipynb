{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import yaml\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    df = pd.DataFrame()\n",
    "    if os.path.isfile(file_path):\n",
    "        # File exists, so read it\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            st.markdown(f\"An error occurred while reading file {file_path}: {e}\")\n",
    "    else:\n",
    "        st.markdown(f\"The file {file_path} does not exist.\")      \n",
    "    return df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['region', 'Resource', 'zone', 'Cluster', 'R_ID', 'Inv_cost_MW',\n",
       "       'Inv_cost_MWh', 'Inv_cost_charge_MW', 'Fixed_OM_cost_MW',\n",
       "       'Fixed_OM_cost_MWh', 'Fixed_OM_cost_charge_MW', 'Var_OM_cost_out',\n",
       "       'Fuel_cost', 'Var_OM_cost_in', 'StartCost', 'Charge_cost',\n",
       "       'CO2SequestrationCost', 'EnergyRevenue', 'SubsidyRevenue',\n",
       "       'OperatingReserveRevenue', 'OperatingRegulationRevenue',\n",
       "       'ReserveMarginRevenue', 'ESRRevenue', 'EmissionsCost',\n",
       "       'RegSubsidyRevenue', 'Revenue', 'Cost', 'Profit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_net_revenue = read_file(\"results/NetRevenue.csv\")\n",
    "cols = df_net_revenue.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot broadcast np.ndarray with operand of type <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mjarada1\\Desktop\\GenX Results Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mjarada1\\Desktop\\GenX Results Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\mjarada1\\Desktop\\GenX Results Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mregion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mjarada1\\Desktop\\GenX Results Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mjarada1\\Desktop\\GenX Results Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mjarada1\\Desktop\\GenX Results Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7238\u001b[0m, in \u001b[0;36mIndex._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   7229\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(other, Index)\n\u001b[0;32m   7230\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_object_dtype(other\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   7234\u001b[0m     \u001b[38;5;66;03m# a chance to implement ops before we unwrap them.\u001b[39;00m\n\u001b[0;32m   7235\u001b[0m     \u001b[38;5;66;03m# See https://github.com/pandas-dev/pandas/issues/31109\u001b[39;00m\n\u001b[0;32m   7236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m-> 7238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mjarada1\\Desktop\\GenX Results Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\mjarada1\\Desktop\\GenX Results Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:283\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\mjarada1\\Desktop\\GenX Results Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:227\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    222\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mjarada1\\Desktop\\GenX Results Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:167\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(y):\n\u001b[1;32m--> 167\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    168\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot broadcast np.ndarray with operand of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mtype\u001b[39m(y)\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    169\u001b[0m         )\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# mask is only meaningful for x\u001b[39;00m\n\u001b[0;32m    172\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(x\u001b[38;5;241m.\u001b[39msize, dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot broadcast np.ndarray with operand of type <class 'list'>"
     ]
    }
   ],
   "source": [
    "cols - [\"region\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCluster\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mR_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "list(cols).remove(['region', 'Resource', 'zone','Cluster', 'R_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute 'remove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcols\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Index' object has no attribute 'remove'"
     ]
    }
   ],
   "source": [
    "cols.remove('region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net_revenue = read_file(\"results/NetRevenue.csv\")\n",
    "df_resources = read_file(\"inputs/resource_list.csv\")\n",
    "resources_list = df_resources[(df_resources.Type == \"Thermal\") & (df_resources.Zone == 1)]\n",
    "\n",
    "df_net_revenue = df_net_revenue.merge(resources_list[[\"Resource\"]], on=\"Resource\", how='inner')\n",
    "cost_list = [col for col in df_net_revenue.columns if \"cost\" in col.lower()]\n",
    "cost_list.remove('EmissionsCost')\n",
    "revenue_list = [col for col in df_net_revenue.columns if \"revenue\" in col.lower()]\n",
    "\n",
    "df_net_revenue[cost_list] = df_net_revenue[cost_list] * -1\n",
    "drop_cols = ['region', 'zone', 'Cluster', 'R_ID', 'Revenue', 'Cost', 'Profit']\n",
    "df_net_revenue.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_cols = [col for col in df_net_revenue.columns if (df_net_revenue[col] == 0).all()]\n",
    "df_net_revenue.drop(columns=zero_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inv_cost_MWh',\n",
       " 'Inv_cost_charge_MW',\n",
       " 'Fixed_OM_cost_MWh',\n",
       " 'Fixed_OM_cost_charge_MW',\n",
       " 'Var_OM_cost_in',\n",
       " 'Charge_cost',\n",
       " 'CO2SequestrationCost',\n",
       " 'SubsidyRevenue',\n",
       " 'OperatingReserveRevenue',\n",
       " 'OperatingRegulationRevenue',\n",
       " 'ESRRevenue',\n",
       " 'RegSubsidyRevenue']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C   D\n",
      "0 -1  4 -7  10\n",
      "1 -2  5 -8  11\n",
      "2 -3  6 -9  12\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9],\n",
    "    'D': [10, 11, 12]\n",
    "})\n",
    "\n",
    "# List of columns to multiply by -1\n",
    "columns_to_multiply = ['A', 'C']\n",
    "\n",
    "# Multiply selected columns by -1\n",
    "df[columns_to_multiply] = df[columns_to_multiply] * -1\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "\n",
    "\n",
    "def read_power():\n",
    "    file_path = \"results/power.csv\"  # Replace with your CSV file path\n",
    "    df_power = pd.DataFrame()\n",
    "    if os.path.isfile(file_path):\n",
    "        # File exists, so read it\n",
    "        try:\n",
    "            df_power = pd.read_csv(file_path)\n",
    "            df_power=df_power.iloc[2:]\n",
    "            df_power.reset_index(drop=True, inplace=True)\n",
    "            df_power = df_power.round(3)\n",
    "        except Exception as e:\n",
    "            st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "    else:\n",
    "        st.markdown(f\"The file {file_path} does not exist.\")   \n",
    "    \n",
    "    return df_power\n",
    "\n",
    "def read_costs():\n",
    "    file_path = \"results\\costs.csv\"  # Replace with your CSV file path\n",
    "    df_costs = pd.DataFrame()\n",
    "    if os.path.isfile(file_path):\n",
    "        # File exists, so read it\n",
    "        try:\n",
    "            df_costs = pd.read_csv(file_path)\n",
    "            df_costs = df_costs.round(3)\n",
    "        except Exception as e:\n",
    "            st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "    else:\n",
    "        st.markdown(f\"The file {file_path} does not exist.\")   \n",
    "    \n",
    "    return df_costs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"results\\Fuel_cost_plant.csv\"  # Replace with your CSV file path\n",
    "df_fuel = pd.read_csv(file_path)\n",
    "df_fuel_total_cost = df_fuel.groupby('Fuel')['AnnualSumCosts'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fuel</th>\n",
       "      <th>AnnualSumCosts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biomass</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_Natural_Gas</td>\n",
       "      <td>827.32188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conventional_DR</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DefaultFuel</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geothermal</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Fuel  AnnualSumCosts\n",
       "0          Biomass         0.00000\n",
       "1   CA_Natural_Gas       827.32188\n",
       "2  Conventional_DR         0.00000\n",
       "3      DefaultFuel         0.00000\n",
       "4       Geothermal         0.00000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fuel_total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resource</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAISO_Advanced_CCGT_candidate</td>\n",
       "      <td>86.021</td>\n",
       "      <td>744.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAISO_Aero_CT_candidate</td>\n",
       "      <td>44.495</td>\n",
       "      <td>585.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAISO_Reciprocating_Engine_candidate</td>\n",
       "      <td>89.825</td>\n",
       "      <td>708.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAISO_Shed_DR_Tranche1</td>\n",
       "      <td>5.526</td>\n",
       "      <td>262.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAM_CAM_RA_i</td>\n",
       "      <td>0.283</td>\n",
       "      <td>7.805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Resource  Revenue     Cost\n",
       "0         CAISO_Advanced_CCGT_candidate   86.021  744.027\n",
       "1               CAISO_Aero_CT_candidate   44.495  585.116\n",
       "2  CAISO_Reciprocating_Engine_candidate   89.825  708.196\n",
       "3                CAISO_Shed_DR_Tranche1    5.526  262.868\n",
       "4                          CAM_CAM_RA_i    0.283    7.805"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    'Resource': ['CAISO_Advanced_CCGT_candidate', 'CAISO_Aero_CT_candidate', 'CAISO_Reciprocating_Engine_candidate', 'CAISO_Shed_DR_Tranche1', 'CAM_CAM_RA_i'],\n",
    "    'Revenue': [86.0206, 44.49509, 89.8247, 5.525751, 0.282928],\n",
    "    'Cost': [744.027, 585.1162, 708.196, 262.8676, 7.804915]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Round all numeric columns to 3 decimal places\n",
    "df = df.round(3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.00314)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_capacity['EndCap']['CAISO_Advanced_CCGT_candidate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_resources = pd.read_csv(\"inputs/resource_list.csv\")\n",
    "\n",
    "selected_type = \"Thermal\"\n",
    "\n",
    "selected_zone = 1\n",
    "resources_list = df_resources[(df_resources.Type == selected_type) & (df_resources.Zone == selected_zone)]\n",
    "\n",
    "df_net_revenue = read_net_revenue().merge(resources_list, on=\"Resource\", how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_co2_emissions = read_co2_emissions()\n",
    "df_co2_emissions_melt = df_co2_emissions.melt(\"Time\", var_name=\"Zone\", value_name=\"Co2 emission\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2_emissions_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_input = \"inputs\\\\resources\\\\policy_assignments\\\\Resource_maximum_capacity_requirement.csv\"  # Replace with your CSV file path\n",
    "df_resources_maxcapreq_input = pd.read_csv(file_path_input)\n",
    "\n",
    "df_resources_maxcapreq_input.set_index(\"Resource\", inplace= True)\n",
    "df_resources_maxcapreq_input_long = df_resources_maxcapreq_input.reset_index().melt(\n",
    "    id_vars=['Resource'],\n",
    "    var_name='Constraint',\n",
    "    value_name='Constraint_Value'\n",
    ")\n",
    "df_resources_maxcapreq_input_long = df_resources_maxcapreq_input_long[df_resources_maxcapreq_input_long[\"Constraint_Value\"]==1]\n",
    "df_resources_maxcapreq_input_long.reset_index(inplace=True, drop=True)\n",
    "df_resources_maxcapreq_input_long = df_resources_maxcapreq_input_long[[\"Resource\",\"Constraint\"]]\n",
    "df_resources_maxcapreq_input_long['Constraint'] = df_resources_maxcapreq_input_long['Constraint'].str.replace(\"Max_Cap\",\"MaxCapReq\")\n",
    "\n",
    "df_resources_maxcapreq_input_long = df_resources_maxcapreq_input_long.merge(policy_max_cap_req()[[\"Constraint\",\t\"ConstraintDescription\"]], how='left', on= \"Constraint\")\n",
    "df_resources_maxcapreq_input_long = df_resources_maxcapreq_input_long[[\"Resource\", \"ConstraintDescription\"]]\n",
    "df_resources_maxcapreq_input_long.rename(columns={\"ConstraintDescription\": \"Constraint\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resources_maxcapreq_input_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_max_cap_req():\n",
    "    file_path_settings = \"inputs\\settings\\genx_settings.yml\"  \n",
    "    df_maxcapreq_input = pd.DataFrame()\n",
    "    df_maxcapreq_results = pd.DataFrame()\n",
    "    \n",
    "    # Open the file and load the YAML content\n",
    "    with open(file_path_settings, 'r') as file:\n",
    "        settings = yaml.safe_load(file)\n",
    "\n",
    "    if 'MaxCapReq' in settings.keys():\n",
    "        file_path_input = \"inputs\\policies\\Maximum_capacity_requirement.csv\"  # Replace with your CSV file path\n",
    "        if os.path.isfile(file_path_input):\n",
    "            # File exists, so read it\n",
    "            try:\n",
    "                df_maxcapreq_input = pd.read_csv(file_path_input)\n",
    "                df_maxcapreq_input.iloc[:,0] = \"MaxCapReq_\"+df_maxcapreq_input.iloc[:,0].astype(str)\n",
    "                df_maxcapreq_input.rename(columns={\"MaxCapReqConstraint\":\"Constraint\"}, inplace = True)\n",
    "            except Exception as e:\n",
    "                st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "\n",
    "        file_path_results = \"results/MaxCapReq_prices_and_penalties.csv\"  # Replace with your CSV file path\n",
    "        if os.path.isfile(file_path_results):\n",
    "            # File exists, so read it\n",
    "            try:\n",
    "                df_maxcapreq_results = pd.read_csv(file_path_results)\n",
    "                df_maxcapreq_input = df_maxcapreq_input.merge(df_maxcapreq_results, on='Constraint', how='left')\n",
    "            except Exception as e:\n",
    "                st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "        else:\n",
    "            st.markdown(f\"The file {file_path_results} does not exist.\")\n",
    "        \n",
    "        return df_maxcapreq_input.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxcapreq_input.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_max_cap_req()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_settings = \"inputs\\settings\\genx_settings.yml\"  \n",
    "df_maxcapreq_input = pd.DataFrame()\n",
    "df_maxcapreq_results = pd.DataFrame()\n",
    "\n",
    "# Open the file and load the YAML content\n",
    "with open(file_path_settings, 'r') as file:\n",
    "    settings = yaml.safe_load(file)\n",
    "\n",
    "if 'MaxCapReq' in settings.keys():\n",
    "    file_path_input = \"inputs\\policies\\Maximum_capacity_requirement.csv\"  # Replace with your CSV file path\n",
    "    df_maxcapreq_input = pd.read_csv(file_path_input)\n",
    "    df_maxcapreq_input.iloc[:,0] = \"MaxCapReq_\"+df_maxcapreq_input.iloc[:,0].astype(str)\n",
    "    df_maxcapreq_input.rename(columns={\"MaxCapReqConstraint\":\"Constraint\"}, inplace = True)\n",
    "\n",
    "\n",
    "    file_path_results = \"results/MaxCapReq_prices_and_penalties.csv\"  # Replace with your CSV file path\n",
    "    df_maxcapreq_results = pd.read_csv(file_path_results)\n",
    "    df_maxcapreq_input = df_maxcapreq_input.merge(df_maxcapreq_results, on='Constraint', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxcapreq_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxcapreq_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_results = \"results/MaxCapReq_prices_and_penalties.csv\"  # Replace with your CSV file path\n",
    "df_maxcapreq_results = pd.read_csv(file_path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxcapreq_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxcapreq_input.iloc[:,0] = \"MaxCapReg_\"+df_maxcapreq_input.iloc[:,0].astype(str)\n",
    "df_maxcapreq_input.rename(columns={\"MaxCapReqConstraint\":\"Constraint\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_results = \"results/MaxCapReq_prices_and_penalties.csv\"  # Replace with your CSV file path\n",
    "df_maxcapreq_results = pd.read_csv(file_path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxcapreq_input.merge(df_maxcapreq_results, on='Constraint', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxcapreq_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    if os.path.isfile(file_path_results):\n",
    "        # File exists, so read it\n",
    "        try:\n",
    "            \n",
    "            df_maxcapreq_output = df_maxcapreq_output.round({'Price':3, 'Slack':3, 'Penalty':3})\n",
    "        except Exception as e:\n",
    "            st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "    else:\n",
    "        st.markdown(f\"The file {file_path_results} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_max_cap_req = dict()\n",
    "\n",
    "file_path = \"inputs\\policies\\Maximum_capacity_requirement.csv\"  # Replace with your CSV file path\n",
    "if os.path.isfile(file_path):\n",
    "    # File exists, so read it\n",
    "    try:\n",
    "        df_max_cap_req = pd.read_csv(file_path)\n",
    "        df_hydro = df_hydro[[\"Resource\",\"Zone\"]]\n",
    "        df_hydro[\"Type\"] = \"Hydro\"\n",
    "        df_resource = pd.concat([df_resource, df_hydro], axis=0)\n",
    "    except Exception as e:\n",
    "        st.markdown(f\"An error occurred while reading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creat resource list\n",
    "df_resource = pd.DataFrame(columns=[\"Resource\", \"Type\",\"Zone\"])\n",
    "\n",
    "file_path = \"inputs/resources/Hydro.csv\"  # Replace with your CSV file path\n",
    "if os.path.isfile(file_path):\n",
    "    # File exists, so read it\n",
    "    try:\n",
    "        df_hydro = pd.read_csv(file_path)\n",
    "        df_hydro = df_hydro[[\"Resource\",\"Zone\"]]\n",
    "        df_hydro[\"Type\"] = \"Hydro\"\n",
    "        df_resource = pd.concat([df_resource, df_hydro], axis=0)\n",
    "    except Exception as e:\n",
    "        st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "\n",
    "file_path = \"inputs/resources/Thermal.csv\"  # Replace with your CSV file path\n",
    "if os.path.isfile(file_path):\n",
    "    # File exists, so read it\n",
    "    try:\n",
    "        df_thermal = pd.read_csv(file_path)\n",
    "        df_thermal = df_thermal[[\"Resource\",\"Zone\"]]\n",
    "        df_thermal[\"Type\"] = \"Thermal\"\n",
    "        df_resource = pd.concat([df_resource, df_thermal], axis=0)\n",
    "    except Exception as e:\n",
    "        st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "\n",
    "file_path = \"inputs/resources/Vre.csv\"  # Replace with your CSV file path\n",
    "if os.path.isfile(file_path):\n",
    "    # File exists, so read it\n",
    "    try:\n",
    "        df_vre = pd.read_csv(file_path)\n",
    "        df_vre = df_vre[[\"Resource\",\"Zone\"]]\n",
    "        df_vre[\"Type\"] = \"Vre\"\n",
    "        df_resource = pd.concat([df_resource, df_vre], axis=0)\n",
    "    except Exception as e:\n",
    "        st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "\n",
    "file_path = \"inputs/resources/Storage.csv\"  # Replace with your CSV file path\n",
    "if os.path.isfile(file_path):\n",
    "    # File exists, so read it\n",
    "    try:\n",
    "        df_storage = pd.read_csv(file_path)\n",
    "        df_storage = df_storage[[\"Resource\",\"Zone\"]]\n",
    "        df_storage[\"Type\"] = \"Storage\"\n",
    "        df_resource = pd.concat([df_resource, df_storage], axis=0)\n",
    "\n",
    "    except Exception as e:\n",
    "        st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "\n",
    "file_path = \"inputs/resources/Flex_demand.csv\"  # Replace with your CSV file path\n",
    "if os.path.isfile(file_path):\n",
    "    # File exists, so read it\n",
    "    try:\n",
    "        df_flex_demand = pd.read_csv(file_path)\n",
    "        df_flex_demand = df_flex_demand[[\"Resource\",\"Zone\"]]\n",
    "        df_flex_demand[\"Type\"] = \"Flex_demand\"\n",
    "        df_resource = pd.concat([df_resource, df_flex_demand], axis=0)\n",
    "    except Exception as e:\n",
    "        st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "\n",
    "file_path = \"inputs/resources/Must_run.csv\"  # Replace with your CSV file path\n",
    "if os.path.isfile(file_path):\n",
    "    # File exists, so read it\n",
    "    try:\n",
    "        df_must_run = pd.read_csv(file_path)\n",
    "        df_must_run = df_must_run[[\"Resource\",\"Zone\"]]\n",
    "        df_must_run[\"Type\"] = \"Must_run\"\n",
    "        df_resource = pd.concat([df_resource, df_must_run], axis=0)\n",
    "    except Exception as e:\n",
    "        st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "\n",
    "file_path = \"inputs/resources/Electrolyzer.csv\"  # Replace with your CSV file path\n",
    "if os.path.isfile(file_path):\n",
    "    # File exists, so read it\n",
    "    try:\n",
    "        df_electrolyzer = pd.read_csv(file_path)\n",
    "        df_electrolyzer = df_electrolyzer[[\"Resource\",\"Zone\"]]\n",
    "        df_electrolyzer[\"Type\"] = \"Electrolyzer\"\n",
    "        df_resource = pd.concat([df_resource, df_electrolyzer], axis=0)\n",
    "\n",
    "    except Exception as e:\n",
    "        st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "\n",
    "file_path = \"inputs/resources/Vre_stor.csv\"  # Replace with your CSV file path\n",
    "if os.path.isfile(file_path):\n",
    "    # File exists, so read it\n",
    "    try:\n",
    "        df_vre_stor = pd.read_csv(file_path)\n",
    "        df_vre_stor = df_vre_stor[[\"Resource\",\"Zone\"]]\n",
    "        df_vre_stor[\"Type\"] = \"Vre_stor\"\n",
    "        df_resource = pd.concat([df_resource, df_vre_stor], axis=0)\n",
    "\n",
    "    except Exception as e:\n",
    "        st.markdown(f\"An error occurred while reading the file: {e}\")\n",
    "\n",
    "df_resource.reset_index(inplace=True, drop=True)\n",
    "df_resource.to_csv(\"inputs/agg_resources.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2_penalties = pd.read_csv(\"results/CO2_prices_and_penalties.csv\")\n",
    "df_esr_penalties = pd.read_csv(\"results/ESR_prices_and_penalties.csv\")\n",
    "df_maxcapreq_penalties = pd.read_csv(\"results/MaxCapReq_prices_and_penalties.csv\")\n",
    "\n",
    "df_co2_penalties.round({\"CO2_Price\":5})\n",
    "df_esr_penalties.round({\"ESR_Price\":5, \"ESR_AnnualSlack\":5, \"ESR_AnnualPenalty\": 5})\n",
    "df_maxcapreq_penalties.round({'Price':3, 'Slack':3, 'Penalty':3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxcapreq_penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxcapreq_penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
